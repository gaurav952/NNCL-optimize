{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_file = pd.read_excel('data_f.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['network theory and filter design', 'fundamentals of data structures', 'fundamentals of data structures', 'electronic measurements', 'digital computer electronics:an introduction to microcomputers', 'electrical engineering materials', 'electronic devices and circuits', 'analysis and design of analog integrated circuits', 'lotus 1-2-3 : quick reference handbook', 'lotus 1-2-3 student workbook and instruction guide', 'optical fiber transmission systems', 'solid state electronic devices', 'interactive computer graphics:data structures, algorithms, languages', 'electrical machines and their applications', 'computer architecture and organization', 'fundamentals of programming languages', 'introduction to digital computer design', 'introduction to operating systems', 'computer programming in cobol', 'programming in pascal']\n"
     ]
    }
   ],
   "source": [
    "from django.utils.encoding import smart_str, smart_unicode\n",
    "book_names = [smart_str(n).lower() for n in data_file['title'] if n!=0]\n",
    "print(book_names[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['network', 'theory', 'and', 'filter', 'design'], ['fundamentals', 'of', 'data', 'structures'], ['fundamentals', 'of', 'data', 'structures'], ['electronic', 'measurements'], ['digital', 'computer', 'electronics', 'an', 'introduction', 'to', 'microcomputers'], ['electrical', 'engineering', 'materials'], ['electronic', 'devices', 'and', 'circuits'], ['analysis', 'and', 'design', 'of', 'analog', 'integrated', 'circuits'], ['lotus', '1', '2', '3', 'quick', 'reference', 'handbook'], ['lotus', '1', '2', '3', 'student', 'workbook', 'and', 'instruction', 'guide'], ['optical', 'fiber', 'transmission', 'systems'], ['solid', 'state', 'electronic', 'devices'], ['interactive', 'computer', 'graphics', 'data', 'structures', 'algorithms', 'languages'], ['electrical', 'machines', 'and', 'their', 'applications'], ['computer', 'architecture', 'and', 'organization'], ['fundamentals', 'of', 'programming', 'languages'], ['introduction', 'to', 'digital', 'computer', 'design'], ['introduction', 'to', 'operating', 'systems'], ['computer', 'programming', 'in', 'cobol'], ['programming', 'in', 'pascal']]\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "tokens = [tokenizer.tokenize(i) for i in book_names]\n",
    "print(tokens[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "num_features = 400    # Word vector dimensionality                      \n",
    "min_word_count = 10  # Minimum word count                        \n",
    "num_workers = 6    # Number of threads to run in parallel\n",
    "context = 200         # Context window size                                                                                    \n",
    "downsampling = 1e-2   # Downsample setting for frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-06 01:17:22,352 : INFO : 'pattern' package not found; tag filters are not available for English\n",
      "2017-12-06 01:17:22,360 : INFO : collecting all words and their counts\n",
      "2017-12-06 01:17:22,362 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-12-06 01:17:22,384 : INFO : PROGRESS: at sentence #10000, processed 50115 words, keeping 4233 word types\n",
      "2017-12-06 01:17:22,426 : INFO : PROGRESS: at sentence #20000, processed 101173 words, keeping 7389 word types\n",
      "2017-12-06 01:17:22,461 : INFO : PROGRESS: at sentence #30000, processed 153298 words, keeping 8502 word types\n",
      "2017-12-06 01:17:22,494 : INFO : PROGRESS: at sentence #40000, processed 202797 words, keeping 8971 word types\n",
      "2017-12-06 01:17:22,518 : INFO : PROGRESS: at sentence #50000, processed 264814 words, keeping 11799 word types\n",
      "2017-12-06 01:17:22,590 : INFO : PROGRESS: at sentence #60000, processed 377400 words, keeping 16267 word types\n",
      "2017-12-06 01:17:22,624 : INFO : PROGRESS: at sentence #70000, processed 447478 words, keeping 18720 word types\n",
      "2017-12-06 01:17:22,647 : INFO : PROGRESS: at sentence #80000, processed 496140 words, keeping 19023 word types\n",
      "2017-12-06 01:17:22,696 : INFO : PROGRESS: at sentence #90000, processed 548630 words, keeping 19291 word types\n",
      "2017-12-06 01:17:22,725 : INFO : collected 20025 word types from a corpus of 608994 raw words and 96563 sentences\n",
      "2017-12-06 01:17:22,726 : INFO : Loading a fresh vocabulary\n",
      "2017-12-06 01:17:22,760 : INFO : min_count=10 retains 3142 unique words (15% of original 20025, drops 16883)\n",
      "2017-12-06 01:17:22,761 : INFO : min_count=10 leaves 573793 word corpus (94% of original 608994, drops 35201)\n",
      "2017-12-06 01:17:22,777 : INFO : deleting the raw counts dictionary of 20025 items\n",
      "2017-12-06 01:17:22,780 : INFO : sample=0.01 downsamples 4 most-common words\n",
      "2017-12-06 01:17:22,782 : INFO : downsampling leaves estimated 524369 word corpus (91.4% of prior 573793)\n",
      "2017-12-06 01:17:22,784 : INFO : estimated required memory for 3142 words and 400 dimensions: 11625400 bytes\n",
      "2017-12-06 01:17:22,809 : INFO : resetting layer weights\n",
      "2017-12-06 01:17:22,943 : INFO : training model with 6 workers on 3142 vocabulary and 400 features, using sg=0 hs=0 sample=0.01 negative=5 window=200\n",
      "2017-12-06 01:17:23,974 : INFO : PROGRESS: at 18.63% examples, 474419 words/s, in_qsize 10, out_qsize 0\n",
      "2017-12-06 01:17:24,987 : INFO : PROGRESS: at 35.48% examples, 459540 words/s, in_qsize 12, out_qsize 0\n",
      "2017-12-06 01:17:25,994 : INFO : PROGRESS: at 51.98% examples, 444770 words/s, in_qsize 11, out_qsize 0\n",
      "2017-12-06 01:17:27,023 : INFO : PROGRESS: at 69.94% examples, 442004 words/s, in_qsize 12, out_qsize 0\n",
      "2017-12-06 01:17:28,032 : INFO : PROGRESS: at 89.95% examples, 457571 words/s, in_qsize 11, out_qsize 0\n",
      "2017-12-06 01:17:28,603 : INFO : worker thread finished; awaiting finish of 5 more threads\n",
      "2017-12-06 01:17:28,647 : INFO : worker thread finished; awaiting finish of 4 more threads\n",
      "2017-12-06 01:17:28,649 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-12-06 01:17:28,653 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-12-06 01:17:28,668 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-12-06 01:17:28,670 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-12-06 01:17:28,672 : INFO : training on 3044970 raw words (2622159 effective words) took 5.7s, 459893 effective words/s\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(tokens, workers=num_workers, \\\n",
    "            size=num_features, min_count = min_word_count, \\\n",
    "            window = context, sample = downsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-06 01:17:29,657 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    }
   ],
   "source": [
    "model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-12-06 01:17:59,741 : INFO : saving Word2Vec object under 300features_40minwords_10context, separately None\n",
      "2017-12-06 01:17:59,744 : INFO : not storing attribute syn0norm\n",
      "2017-12-06 01:17:59,746 : INFO : not storing attribute cum_table\n",
      "2017-12-06 01:17:59,872 : INFO : saved 300features_40minwords_10context\n"
     ]
    }
   ],
   "source": [
    "model_name = \"300features_40minwords_10context\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('effective', 0.7903382778167725),\n",
       " ('interaction', 0.7681287527084351),\n",
       " ('administration', 0.7244318723678589),\n",
       " ('financial', 0.6917579770088196),\n",
       " ('organisation', 0.6910723447799683),\n",
       " ('organizational', 0.6895462274551392),\n",
       " ('personnel', 0.6874874830245972),\n",
       " ('innovation', 0.6839104294776917),\n",
       " ('knowledge', 0.6813844442367554),\n",
       " ('vedamrit', 0.6796798706054688)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"human\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 0.7956965565681458),\n",
       " ('ph', 0.7767686247825623),\n",
       " ('sri', 0.7733452320098877),\n",
       " ('peace', 0.7711155414581299),\n",
       " ('stories', 0.7608237266540527),\n",
       " ('hindu', 0.7562004327774048),\n",
       " ('philosophy', 0.7535654306411743),\n",
       " ('god', 0.7371869087219238),\n",
       " ('nations', 0.7351016998291016),\n",
       " ('literature', 0.7350578308105469)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.most_similar(\"life\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'machine'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.doesnt_match(\"machine business managerial vector engineering cost\".split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------END---------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"---------------------END---------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
